# 챕터3 신경망
신경망  
\- 퍼셉트론은 가중치를 사람이 수동으로 설정해줘야 함  
\- 신경망은 가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습하는 능력을 가짐

활성화 함수: 입력 신호의 총합을 출력 신호로 변환하는 함수  

계단 함수  
\- 임계값을 경계로 출력이 바뀌는 함수  
\- 0을 경계로 갑자기 변화  
\- 0과 1 중 하나의 값만 돌려줌  
\- 비선형 함수  

시그모이드 함수  
\- 신경망에서 자주 이용하는 활성화 함수  
\- h(x) = 1/1+exp(-x) (e는 자연상수=2.7182...)  
\- 시그모이드란 S자 모양이란 뜻  
\- 입력에 따라 출력이 연속적으로 변화  
\- 값을 실수로 돌려줌  
\- 비선형 함수  

ReLU 함수  
\- 입력이 0을 넘으면 그대로 출력, 0이하이면 0으로 출력하는 함수  
  
다차원 배열  
\- 기본적으로 '숫자의 집합'임  
\- 1차원 배열은 벡터  
\- 2차원 배열은 행렬  
\- 3차원 배열은 텐서라고함  
\- 가로는 행(row), 세로는 열(column)  
  
소프트맥스 함수  
\- 소프트맥스 함수의 분자는 입력신호의 지수 함수, 분모는 모든 입력 신호의 지수 함수의   합으로 구성
\- 소프트맥스의 출력은 모든 입력 신호로부터 영향을 받음  
\- 함수의 출력은 0에서 1.0 사이의 실수  
\- 출력 총합이 1 (중요한 성질)  
\- 위의 성질로 함수의 출력을 '확률'로 해석 가능  
  
MNIST dataset  
\- 0~9까지의 숫자로 이루어진 이미지 데이터 베이스  
\- 이 데이터를 통해 신경망 실습함  
\- 데이터는 책에서 제공하는 파일로 다운로드함  
  
정규화: 데이터를 특정 범위로 변화하는 처리  
  
전처리: 신경망의 입력 데이터에 특정 변환을 가하는 것  
  
배치  
\- 하나로 묶은 입력 데이터  
\- 컴퓨터로 계산할 때 큰 이점을 줌  
\- 배치 처리를 함으로써 부하를 줄여줌  

---
## 3장 정리
- 신경망에서는 활성화 함수로 시그모이드(*Sigmoid*) 함수와 렐루(*ReLU*) 함수 같은 매끄럽게 변화하는 함수를 이용
- 기계학습 문제는 크게 '회귀'와 '분류'로 나뉨
- 회귀에서는 주로 항등 함수, 분류에서는 주로 소프트맥스 함수를 이용
- 입력 데이터를 묶은 것을 '배치'라 하며, 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있음