# 챕터4 신경망 학습
머신러닝에서의 학습: 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것

손실 함수  
-신경망이 학습할 수 있도록 해주는 지표  
-결괏값을 가장 작게 만드느 가중치 매개변수를 찾는 것이 목표  
-오차제곱함, 교차 엔트로피 오차를 손실 함수로써 자주 이용함  
  
원-핫 인코딩: 한 원소만 1로 하고 그 외에는 0으로 나타내는 표기법(여기서 말하는 원소  1은 정답을 의미함)
  
신경망을 학습할 때 정확도를 지표로 삼지 않고, 손실함수를 지표로 사용하는 이유는  
정화도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 떄문이다.  
  
수치 미분  
-미분은 '특정 순간'의 변화량을 뜻함(기울기를 구하는것과 같음)  
-해석적 미분은 오차를 포함하지 않는 미분값을 구해줌  
-수치 미분은 근사치를 구하는 것  
  
편미분  
-변수가 여럿인 함수에 대한 미분  
-미분과 마찬가지로 특정 장소의 기울기를 구함  
-기호는 a(라운드)  
  
기울기  
-모든 변수의 편미분을 벡터로 정리한 것  
  
경사법  
-기울기를 잘 이용해 함수의 최솟값을 찾으려는 방법  
-기울기는 함수의 값을 낮추는 방안을 제시하는 지표  
-현 위치에서 기울어진 방향으로 일정 거리만큼 이동, 다시 기울기를 구한다. 이 방법을 반복하여 함수의 값을 점차 줄이는 것이 경사법
  
학습률  
-매개변수 값을 얼마나 갱신하느냐를 정하는 값  
-너무 크거나, 작으면 올바른 학습이 어려움  
-학습률을 지표로 올바르게 학습하고 있는지 확인  
  
하이퍼파라미터  
-학습률 같은 사람이 직접 설정해야하는 매개변수  

---
신경망 학습의 절차   

전제  
-신경망에는 가중치와 편향이 있고, 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'
  
1단계 - 미니배치  
-훈련 데이터 중 일부를 무작위로 가져옵니다. 손실 함수 값을 줄이는 것이 목표  
  
2단계 - 기울기 산출  
미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시
  
3단계 - 매개변수 갱신  
-기울기 방향으로 아주 조금 갱신  
  
4단계 - 반복  
-1~3단계를 반복  

---

확률적 경사 하강법(SGD)  
-미니배치로 무작위로 선정한 데이터를 경사하강법으로 매개변수를 갱신하는 방법  
  
오버피팅  
-훈련 데이터를 과하게 학습하여, 훈련 데이터의 정확성은 높으나 다른 데이터셋에선 정확한 학습이 되지 않은 상태
  
에폭(epoch)  
-학습에서 훈련 데이터를 모두 소진했을 때의 횟수  

---
### two_layer_net 클래스의 인스턴트 변수
|인스턴트 변수||설명|
|---|---|---|
|params||신경망의 매개변수를 보관하는 딕셔너리 변수(인스턴스 변수) <br>params['W1']은 1번째 층의 가중치, params['b1']은 1번째 층의 편향<br>params['W2']은 2번째 층의 가중치, params['b2']은 2번째 층의 편향|
|grads||기울기 보관하는 딕셔너리 변수(numerical_gradient() 메서드의 반환 값<br>grads['W1']은 1번째 층의 가중치의 기울기, grads['b1']은 1번째 층의 편향의 기울기<br>grads['W2']은 2번째 층의 가중치의 기울기, grads['b2']은 2번째 층의 편향의 기울기

---
---
### two_layer_net 클래스의 메서드
|인스턴트 변수||설명|
|---|---|---|
|\__init__(self, input_size, hidden_size, output_size)||초기화를 수행한다.<br>인수는 앞에서부터 입력층 뉴런 수, 은닉층 뉴런 수, 출력층 뉴런 수|
|predict(self, x)||예측(추론)을 수행한다.<br>인수 x는 이미지 데이터|
|loss(self, x, t)||손실 함수의 값을 구한다.<br>인수 x는 이미지 데이터, t는 정답 레이블|
|accuracy(self, x, t)||정확도를 구한다.|
|numerical_gradient(self, x, t)||가중치 매개변수의 기울기를 수치 미분 방식으로 구한다|
|gradient(self, x, t)||가중치 매개변수의 기울기를 오차역전파법으로 구한다.<br>구현은 다음 장에서|

---
## 4장 정리
- 기계학습에서 사용하는 데이터셋은 '훈련 데이터'와 '시험 데이터'로 나눠 사용
- 신경망 학습은 '손실 함수'를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신
- 갱신할 때는 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복
- 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 '수치 미분'이라고 함
- 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있음
- 수치 미분을 이용한 계산에는 시간이 걸리지만 쉽고, 오차역전파법은 기울기를 고속으로 구할 수 있음