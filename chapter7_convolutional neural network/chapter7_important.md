# 챕터7 합성곱 신경망  

## **CNN(합성곱 신경망)**  
\- CNN은 이미지 인식, 음성 인식 등에 사용  
\- 이미지 인식 분야에서 딥러닝을 활용한 기법은 대부분 CNN을 기초로 함  

### **CNN 구조**  
\- '합성곱 계층'과 '풀링 계층'이 있음  
\- 지금까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합이 되어있는데, 이를 **완전연결** 이라고 함  

### **완전연결 계층으로 이뤄진 네트워크(Affine 계층)**

---
- 데이터 --> Affine->ReLU --> Affine->ReLU --> Affine->ReLU --> Affine->ReLU --> Affine->Softmax -->  


### **CNN으로 이뤄진 네트워크**

---
- 데이터 --> Conv->ReLU->Pooling --> Conv->ReLU->Pooling -->  Conv->ReLU --> Affine->ReLU --> Affine->Softmax -->  

## **합성곱 계층**  
\- 패딩(padding), 스트라이드(stride) 등 CNN 고유의 용어가 등장함  
\- 합성곱 계층의 입출력 데이터를 '특징 맵'이라고도 함  
\- 입력 데이터를 '입력 특징 맵', 출력 데이터를 '출력 특징 맵'  

### **완전연결 계층의 문제점**  
\- 데이터 형상을 무시함  
\- 이미지는 3차원 형상이며, 3차원 속에서 의미를 갖는 본질적인 패턴이 있음  
\- 완전연결 계층은 형상을 무시하고 모든 입력 데이터를 동등한 뉴런(같은 차원 뉴런)으로 취급하여 형상에 담긴 정보를 살릴 수 없음  
\- 합성곱 계층은 형상을 유지하여 이미지처럼 형상을 가진 데이터를 제대로 이해할 가능성이 있음  

### **합성곱 연산**  
- 합성곱 연산 단계
1. 입력 데이터에 필터를 적용  
2. 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용  
3. 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구하고(단일 곱셈-누산), 결과를 출력의 해당 장소에 저장  
4. 이 과정을 모든 장소에서 수행하면 합성곱 연산의 출력이 완성  

\- CNN에서는 필터의 매개변수가 그동안의 '가중치'에 해당  
\- 편향도 존재

### **패딩** 
\- 폭이 1짜리 패딩이라 하면, 입력 데이터 사방 1픽셀을 특정 값으로 채우는 것  
\- 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(ex. 0)으로 채우기도 함  
\- 주로 출력 크기를 조정할 목적으로 사용  
\- 합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력 크기가 1이되어 연산을 적용할 수 없는 상황이 생기기 때문  

### **스트라이드**  
\- 필터(윈도우)를 적용하는 위치의 간격  
\- 스트라이드를 키우면 출력 크기가 작아짐  

### **패딩과 스트라이드의 상관관계**  
\- 패딩은 출력 크기를 키우고, 스트라이드는 출력 크기를 줄임  
\- 이러한 관계를 수식화 하면  

---
**입력 크기(H, W), 필터 크기(FH, FW), 출력 크기(OH, OW), 패딩을 P, 스트라이드를 S라 할 때,**  
- ### OH = $H + 2P - FH\over S $ + 1  
- ### OW = $W + 2P - FW\over S $ + 1  
---
\- 위의 식이 반드시 정수로 나눠 떨어져야함  

## **3차원 합성곱**  

\- 입력 데이터의 채널 수와 필터의 채널 수가 같아야 함  

### **블록처럼 생각하기**  

\- 3차원 합성곱 연산은 직육면체 블록이라고 생각하면 쉬움, 블록은 3차원 직육면체  
\- 3차원 데이터를 다차원 배열로 나타낼 때는 채널, 높이, 너비(C, H, W)로 표기  

### **배치 처리**  

\- 배치 처리 시에 데이터의 선두에 배치용 차원을 추가하여 연산  
\- 신경망에서 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 이뤄져, N회 분의 처리를 한번에 수행

## **풀링 계층**  

\- 세로, 가로 방향의 공간을 줄이는 연산  
\- 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통  

### **2X2 최대 풀링**  

\- 최대 풀링은 최댓값을 구하는 연산  
\- 2X2는 대상 영역의 크기  
\- 2X2 최대 풀링은 2X2 크기의 영역에서 가장 큰 원소를 하나 꺼냄  

### **평균 풀링**  

\- 대상 영역의 평균을 계산하는 연산  

## **풀링 계층의 특징** 

### 학습해야 할 매개변수가 없다.
- 대상 영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없음

### 채널 수가 변하지 않는다.
- 채널마다 독립적으로 계산하기 때문에 입력 데이터의 채널 수 그대로 출력 데이터를 내보냄

### 입력의 변화에 영향을 적게 받는다.
- 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않음

## **합성곱/풀링 계층 구현하기**